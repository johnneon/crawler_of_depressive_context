# Веб-интерфейс для краулера депрессивного контекста

Это веб-приложение на базе Streamlit, которое предоставляет удобный графический интерфейс для работы с краулером депрессивного контекста ВКонтакте.

## Возможности

- Интуитивно понятный пошаговый интерфейс для запуска краулера
- Ввод списка пользователей вручную или через файл
- Настройка параметров краулинга (глубина сбора, видимость браузера)
- Отображение процесса краулинга в режиме реального времени
- Просмотр результатов анализа с возможностью скачивания в JSON-формате

## Запуск приложения

Для запуска приложения выполните следующую команду из корневой директории проекта:

```bash
streamlit run app/app.py
```

## Использование

1. В интерфейсе приложения введите список пользователей для анализа (ID или URL-адреса) или загрузите файл со списком пользователей
2. Введите данные для входа в ВКонтакте (логин и пароль)
3. Настройте дополнительные параметры (количество прокруток, видимость браузера)
4. Нажмите кнопку "Запустить краулинг"
5. Дождитесь завершения процесса и просмотрите результаты

## Структура приложения

Приложение имеет модульную структуру, разделенную на логические компоненты:

```
app/
|-- app.py                   # Основная точка входа
|-- common/                  # Общие компоненты
|   |-- __init__.py
|   |-- session.py           # Управление сессией и состоянием
|   |-- ui.py                # Общие UI компоненты
|   |-- crawler.py           # Утилиты для работы с краулером
|-- steps/                   # Шаги приложения
|   |-- __init__.py
|   |-- step1_users.py       # Шаг 1: Ввод пользователей
|   |-- step2_auth.py        # Шаг 2: Аутентификация
|   |-- step3_params.py      # Шаг 3: Параметры
|   |-- step4_crawler.py     # Шаг 4: Запуск и результаты
```

### Описание модулей

#### common/session.py
Управление состоянием приложения, инициализация сессии, функции для переходов между шагами.

#### common/ui.py
Общие компоненты пользовательского интерфейса, настройка страницы, информационные блоки.

#### common/crawler.py
Функции для взаимодействия с краулером: формирование команды, запуск процесса, отображение результатов.

#### steps/step1_users.py - steps/step4_crawler.py
Отдельные шаги пользовательского интерфейса, каждый в своем модуле для лучшей организации кода.

## Требования

- Python 3.7+
- Установленные зависимости из requirements.txt
- Доступ к интернету и ВКонтакте 