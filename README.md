# Система анализа депрессивного контекста

Проект содержит инструменты для сбора, анализа и классификации текстовых данных на предмет наличия признаков депрессии с использованием методов машинного обучения.

## Структура проекта

- **[crawler/](crawler/README.md)** - модуль для сбора данных из социальных сетей
  - **main.py** - основной скрипт краулера для сбора постов и профилей VK
  - **README.md** - документация по использованию краулера
- **[cleaner/](cleaner/README.md)** - модуль для очистки, подготовки и разметки данных
  - **main.py** - скрипт обработки и маркировки депрессивного контента
- **[ml/](ml/README.md)** - модуль машинного обучения для анализа депрессивного контекста
  - **preprocessing.py** - функции для предобработки текстовых данных
  - **dataset.py** - класс для работы с данными
  - **model.py** - архитектура нейронной модели с механизмом внимания
  - **balancing.py** - методы балансировки выборок
  - **training.py** - функции для обучения и оценки модели
  - **prediction.py** - класс для получения предсказаний
  - **train.py** - скрипт для обучения модели
  - **predict.py** - скрипт для получения предсказаний
  - **visualization.py** - функции для визуализации результатов
  - **visualize_data.py** - скрипт для анализа и визуализации данных
- **[app/](app/README.md)** - веб-интерфейс для проекта на базе Streamlit
  - **app.py** - основной скрипт веб-приложения
  - **README.md** - документация по использованию веб-интерфейса
- **[models/](models/)** - директория для сохранения обученных моделей
  - **depression_model.pt** - обученная модель для определения депрессивного контекста
- **[results/](results/)** - директория с результатами работы и научной документацией
  - **[data_preprocessing.md](results/data_preprocessing.md)** - документация по предобработке данных
  - **[model_training.md](results/model_training.md)** - документация по процессу обучения модели
  - **results.json** - файл с результатами работы модели
  - **metrics.png** - график метрик обучения
  - **loss.png** - график функции потерь
- **[visualizations/](visualizations/)** - директория для визуализаций и графиков
  - **wordclouds/** - облака слов для анализа классов
  - **top_words/** - визуализации наиболее частых слов
  - **metrics_summary.txt** - итоговые метрики модели
  - **loss_plot.png** - график изменения функции потерь
  - **metrics_plot.png** - графики изменения метрик
- **data_analyze.ipynb** - Jupyter Notebook для анализа собранных данных
- **main.py** - точка входа в проект
- **requirements.txt** - файл зависимостей проекта

## Модули проекта

### Краулер данных ([crawler/](crawler/README.md))

Модуль предназначен для сбора текстовых данных и профилей пользователей из социальной сети ВКонтакте. Обеспечивает автоматизированный сбор постов, включая метаданные пользователей (пол, город, количество подписчиков, отношение к алкоголю и курению, главное в жизни и людях). Поддерживает авторизацию с двухфакторной аутентификацией и сохранение результатов в структурированный JSON формат.

### Очистка и маркировка данных ([cleaner/](cleaner/README.md))

Модуль для предварительной обработки, очистки и автоматической маркировки собранных данных:

1. **Очистка текста постов** - удаление ссылок, специальных символов и лишних пробелов
2. **Идентификация депрессивного контента** - анализ текстов на основе лексических маркеров
3. **Структурирование данных пользователя** - выделение релевантных атрибутов и метаданных
4. **Анонимизация данных** - замена реальных идентификаторов на последовательные числа

Используются следующие категории ключевых слов для определения депрессивного контекста:
- **Лексические** - явные упоминания депрессии, чувства усталости, бессмысленности
- **Изоляция** - выражения одиночества, ощущения брошенности
- **Самоориентированные** - высказывания о своей пустоте, беспомощности
- **Структурные** - короткие фрагментированные высказывания о боли, отсутствии сил или смысла
- **Физиологические** - упоминания о проблемах со сном, аппетитом, физической активностью

Система проверяет как русскоязычные, так и англоязычные ключевые слова, что повышает точность выявления депрессивного контента.

### Модуль машинного обучения ([ml/](ml/README.md))

Центральный модуль проекта, реализующий полный цикл обработки и анализа данных:

1. **Предобработка данных** - очистка текстов, токенизация, лемматизация, удаление стоп-слов
2. **Балансировка выборок** - методы работы с несбалансированными данными (SMOTE, аугментация)
3. **Обучение модели** - двунаправленная LSTM с механизмом внимания
4. **Оценка качества** - расчет метрик (accuracy, precision, recall, F1, AUC)
5. **Визуализация результатов** - построение графиков, облаков слов, анализ распределений

### Анализ данных (data_analyze.ipynb)

Jupyter Notebook содержит исследовательский анализ собранного датасета, включая:
- Статистику распределения классов (1327 положительных и 84587 отрицательных примеров)
- Распределение длины текстов
- Анализ метаданных пользователей
- Визуализации ключевых характеристик данных

## Архитектура модели

Система использует двунаправленную LSTM с механизмом внимания для обработки текста и дополнительно учитывает метаданные пользователя:

- **Текстовые эмбеддинги** - предобученные FastText векторы (300 размерность)
- **Двунаправленная LSTM** - 2 слоя с размерностью скрытого состояния 128
- **Механизм внимания** - выделяет наиболее значимые для классификации части текста
- **Обработка метаданных** - отдельный энкодер с многослойным перцептроном
- **Классификатор** - объединяет текстовые и метаданные признаки

Детальное описание архитектуры модели и процесса обучения доступно в [документации по обучению модели](results/model_training.md).

## Методы балансировки данных

Для борьбы с дисбалансом классов (соотношение 1:64) используются следующие подходы:
- **Аугментация положительных примеров** (методы удаления и перестановки слов)
- **Частичный SMOTE** - генерация синтетических примеров миноритарного класса
- **Взвешивание функции потерь** - больший штраф за ошибки на миноритарном классе

Подробное описание методов предобработки данных доступно в [документации по предобработке](results/data_preprocessing.md).

## Установка зависимостей

```bash
pip install -r requirements.txt
```

## Предварительные требования

### FastText модель

Для работы требуется предобученная модель FastText для русского языка (`cc.ru.300.bin`), которая используется для создания эмбеддингов текста.

#### Где скачать модель FastText:

1. Официальный сайт FastText: https://fasttext.cc/docs/en/crawl-vectors.html
2. Прямая ссылка на скачивание: https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.bin.gz

После скачивания распакуйте файл:
```bash
gzip -d cc.ru.300.bin.gz
```

Поместите распакованный файл `cc.ru.300.bin` в корневую директорию проекта или укажите путь к нему при запуске скриптов.

## Использование

### Сбор данных

```bash
python -m crawler.main --login ваш_логин --password ваш_пароль --user username --scrolls 5 --output dataset/data.json
```

### Веб-интерфейс для сбора данных

Для запуска веб-интерфейса:
```bash
python run_app.py
```
или
```bash
streamlit run app/app.py
```

Веб-интерфейс предоставляет удобный графический интерфейс для:
- Ввода списка пользователей для анализа (ID или ссылки на профили)
- Ввода учетных данных ВКонтакте
- Настройки параметров краулинга
- Мониторинга процесса сбора данных в реальном времени
- Просмотра и скачивания результатов анализа

### Очистка и маркировка данных

```bash
python -m cleaner.main data
```

Для обработки нескольких директорий:
```bash
python -m cleaner.main data1 data2 data3
```

### Визуализация данных

```bash
python -m ml.visualize_data --data_path dataset/data.json --output_dir visualizations/data --generate_wordclouds --analyze_top_words
```

### Обучение модели

Базовое обучение с балансировкой:
```bash
python -m ml.train --data_path dataset/data.json --fasttext_path cc.ru.300.bin --epochs 20 --balance_method partial_smote
```

Обучение с обработкой выбросов и аугментацией данных:
```bash
python -m ml.train --data_path dataset/data.json --fasttext_path cc.ru.300.bin --epochs 20 --balance_method partial_smote --handle_outliers --augment_positive
```

### Получение предсказаний

```bash
python -m ml.predict --model_path models/depression_model.pt --input_file new_data.json --output_file results/predictions.json
```

### Визуализация результатов

```bash
python -m ml.visualization --results_file results/results.json --output_dir visualizations/results
```

## Метрики качества модели

На тестовой выборке модель демонстрирует следующие метрики:
- **Accuracy (точность)**: 0.9873
- **Precision (точность классификации)**: 0.8986
- **Recall (полнота)**: 0.9274
- **F1-мера**: 0.9128
- **ROC-AUC**: 0.9869

## Подробная документация

Подробная документация о процессе обучения модели и предобработке данных доступна в следующих файлах:
- [Предобработка данных](results/data_preprocessing.md)
- [Обучение модели](results/model_training.md)
- [Очистка и маркировка данных](cleaner/README.md)

## Авторы

Проект разработан для анализа депрессивного контекста в текстовом контенте пользователей социальных сетей. Целью является раннее выявление признаков депрессии на основе лингвистических маркеров в публикациях пользователей.